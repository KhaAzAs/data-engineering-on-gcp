{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and Validate ELT Data Pipeline using Dataproc\n",
    "\n",
    "Let us go ahead and run the ELT Data Pipeline using Dataproce Workflow Template and also validate to see if the Pipeline is successfully run as per the requirements. We will clean up all the workflow runs before taking care of the run and validation of the ELT Data Pipeline.\n",
    "* Step 1: Pre-run Validation\n",
    "* Step 2: Run ELT Data Pipeline using Dataproc Workflow Template\n",
    "* Step 3: Post-run Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.dataproc) Command name argument expected.\n",
      "\n",
      "Available groups for gcloud dataproc:\n",
      "\n",
      "      autoscaling-policies    Create and manage Dataproc autoscaling policies.\n",
      "      batches                 Submit Dataproc batch jobs.\n",
      "      clusters                Create and manage Dataproc clusters.\n",
      "      jobs                    Submit and manage Dataproc jobs.\n",
      "      node-groups             Manage Dataproc node groups.\n",
      "      operations              View and manage Dataproc operations.\n",
      "      workflow-templates      Create and manage Dataproc workflow templates.\n",
      "\n",
      "For detailed information on this command and its flags, run:\n",
      "  gcloud dataproc --help\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.dataproc.operations) Command name argument expected.\n",
      "\n",
      "Available commands for gcloud dataproc operations:\n",
      "\n",
      "      cancel                  Cancel an active operation.\n",
      "      delete                  Delete the record of an inactive operation.\n",
      "      describe                View the details of an operation.\n",
      "      get-iam-policy          Get IAM policy for an operation.\n",
      "      list                    View the list of all operations.\n",
      "      set-iam-policy          Set IAM policy for an operation.\n",
      "\n",
      "For detailed information on this command and its flags, run:\n",
      "  gcloud dataproc operations --help\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Listed 0 items.\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc operations list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "metadata:\n",
      "  '@type': type.googleapis.com/google.cloud.dataproc.v1.WorkflowMetadata\n",
      "  clusterUuid: d1f87e3a-5d73-4d88-b893-fc5dee563e03\n",
      "  endTime: '2024-04-21T07:30:35.777976Z'\n",
      "  graph:\n",
      "    nodes:\n",
      "    - jobId: job-cleanup-ofco6qajm5lzy\n",
      "      state: COMPLETED\n",
      "      stepId: job-cleanup\n",
      "    - jobId: job-convert-orders-ofco6qajm5lzy\n",
      "      prerequisiteStepIds:\n",
      "      - job-cleanup\n",
      "      state: COMPLETED\n",
      "      stepId: job-convert-orders\n",
      "    - jobId: job-convert-order-items-ofco6qajm5lzy\n",
      "      prerequisiteStepIds:\n",
      "      - job-cleanup\n",
      "      state: COMPLETED\n",
      "      stepId: job-convert-order-items\n",
      "    - jobId: job-daily-product-revenue-ofco6qajm5lzy\n",
      "      prerequisiteStepIds:\n",
      "      - job-convert-orders\n",
      "      - job-convert-order-items\n",
      "      state: COMPLETED\n",
      "      stepId: job-daily-product-revenue\n",
      "  startTime: '2024-04-21T07:27:57.378621Z'\n",
      "  state: DONE\n",
      "  template: wf-daily-product-revenue\n",
      "  version: 6\n",
      "name: projects/wired-method-417107/regions/asia-southeast2/operations/8d3e85c4-768e-34cb-8e6f-3bdf7f916916\n",
      "response:\n",
      "  '@type': type.googleapis.com/google.protobuf.Empty\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc operations describe 8d3e85c4-768e-34cb-8e6f-3bdf7f916916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleted [f264d113-9047-472e-9109-1062dd6859d2].\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc operations delete f264d113-9047-472e-9109-1062dd6859d2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/4f5312af94d64609b6b2aa065e25dc42/\n",
      "driverOutputResourceUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/4f5312af94d64609b6b2aa065e25dc42/driveroutput\n",
      "jobUuid: e405f007-fd9c-35a3-8aa2-36a24c9cb031\n",
      "placement:\n",
      "  clusterName: khazdataprocdev\n",
      "  clusterUuid: d1f87e3a-5d73-4d88-b893-fc5dee563e03\n",
      "reference:\n",
      "  jobId: 4f5312af94d64609b6b2aa065e25dc42\n",
      "  projectId: wired-method-417107\n",
      "sparkSqlJob:\n",
      "  queryFileUri: gs://khazretail/scripts/daily_product_revenue/cleanup.sql\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2024-04-21T07:43:41.790480Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2024-04-21T07:43:14.140709Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2024-04-21T07:43:14.178023Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2024-04-21T07:43:14.467308Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.184.0.2\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal.:8088/proxy/application_1711307687799_0047/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [4f5312af94d64609b6b2aa065e25dc42] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "24/04/21 07:43:22 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/04/21 07:43:22 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/04/21 07:43:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/04/21 07:43:22 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark Web UI available at http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal:33641\n",
      "Spark master: yarn, Application Id: application_1711307687799_0047\n",
      "Time taken: 6.464 seconds\n",
      "Time taken: 0.52 seconds\n",
      "Job [4f5312af94d64609b6b2aa065e25dc42] finished successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=khazdataprocdev -f gs://khazretail/scripts/daily_product_revenue/cleanup.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2024-04-21T07:04:04.406256Z'\n",
      "id: wf-daily-product-revenue\n",
      "jobs:\n",
      "- sparkSqlJob:\n",
      "    queryFileUri: gs://khazretail/scripts/daily_product_revenue/cleanup.sql\n",
      "  stepId: job-cleanup\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://khazretail/scripts/daily_product_revenue/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://khazretail\n",
      "      table_name: orders\n",
      "  stepId: job-convert-orders\n",
      "- prerequisiteStepIds:\n",
      "  - job-cleanup\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://khazretail/scripts/daily_product_revenue/file_format_converter.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://khazretail\n",
      "      table_name: order_items\n",
      "  stepId: job-convert-order-items\n",
      "- prerequisiteStepIds:\n",
      "  - job-convert-orders\n",
      "  - job-convert-order-items\n",
      "  sparkSqlJob:\n",
      "    queryFileUri: gs://khazretail/scripts/daily_product_revenue/compute_daily_product_revenue.sql\n",
      "    scriptVariables:\n",
      "      bucket_name: gs://khazretail\n",
      "  stepId: job-daily-product-revenue\n",
      "name: projects/wired-method-417107/regions/asia-southeast2/workflowTemplates/wf-daily-product-revenue\n",
      "placement:\n",
      "  clusterSelector:\n",
      "    clusterLabels:\n",
      "      goog-dataproc-cluster-name: khazdataprocdev\n",
      "updateTime: '2024-04-21T07:20:52.444556Z'\n",
      "version: 6\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc workflow-templates describe wf-daily-product-revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting on operation [projects/wired-method-417107/regions/asia-southeast2/operations/a75cbe2a-84c2-3ec2-a46b-a45242d31fd9].\n",
      "WorkflowTemplate [wf-daily-product-revenue] RUNNING\n",
      "Job ID job-cleanup-ghg6ir5m2kcgy RUNNING\n",
      "Job ID job-cleanup-ghg6ir5m2kcgy COMPLETED\n",
      "Job ID job-convert-orders-ghg6ir5m2kcgy RUNNING\n",
      "Job ID job-convert-order-items-ghg6ir5m2kcgy RUNNING\n",
      "Job ID job-convert-order-items-ghg6ir5m2kcgy COMPLETED\n",
      "Job ID job-convert-orders-ghg6ir5m2kcgy COMPLETED\n",
      "Job ID job-daily-product-revenue-ghg6ir5m2kcgy RUNNING\n",
      "WorkflowTemplate [wf-daily-product-revenue] DONE\n",
      "Job ID job-daily-product-revenue-ghg6ir5m2kcgy COMPLETED\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc workflow-templates instantiate wf-daily-product-revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/f05ace9b6958472d89f198540965f921/\n",
      "driverOutputResourceUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/f05ace9b6958472d89f198540965f921/driveroutput\n",
      "jobUuid: be4c60fd-67ab-3c73-bd38-2dd1420e93c8\n",
      "placement:\n",
      "  clusterName: khazdataprocdev\n",
      "  clusterUuid: d1f87e3a-5d73-4d88-b893-fc5dee563e03\n",
      "reference:\n",
      "  jobId: f05ace9b6958472d89f198540965f921\n",
      "  projectId: wired-method-417107\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - SHOW databases\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2024-04-21T07:51:21.405237Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2024-04-21T07:50:56.051913Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2024-04-21T07:50:56.085984Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2024-04-21T07:50:56.316867Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.184.0.2\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal.:8088/proxy/application_1711307687799_0052/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [f05ace9b6958472d89f198540965f921] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "24/04/21 07:51:03 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/04/21 07:51:03 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/04/21 07:51:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/04/21 07:51:03 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark Web UI available at http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal:37081\n",
      "Spark master: yarn, Application Id: application_1711307687799_0052\n",
      "default\n",
      "retail_bronze_db\n",
      "retail_gold_db\n",
      "Time taken: 6.129 seconds, Fetched 3 row(s)\n",
      "Job [f05ace9b6958472d89f198540965f921] finished successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=khazdataprocdev -e \"SHOW databases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/3b57877c821e40c183427f9a57b1225c/\n",
      "driverOutputResourceUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/3b57877c821e40c183427f9a57b1225c/driveroutput\n",
      "jobUuid: 523a1b41-a4d4-317f-9a59-35e755e49060\n",
      "placement:\n",
      "  clusterName: khazdataprocdev\n",
      "  clusterUuid: d1f87e3a-5d73-4d88-b893-fc5dee563e03\n",
      "reference:\n",
      "  jobId: 3b57877c821e40c183427f9a57b1225c\n",
      "  projectId: wired-method-417107\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - USE retail_bronze_db;SHOW tables\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2024-04-21T07:52:56.441819Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2024-04-21T07:52:26.483189Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2024-04-21T07:52:26.516224Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2024-04-21T07:52:26.780357Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.184.0.2\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal.:8088/proxy/application_1711307687799_0053/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [3b57877c821e40c183427f9a57b1225c] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "24/04/21 07:52:33 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/04/21 07:52:34 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/04/21 07:52:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/04/21 07:52:34 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark Web UI available at http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal:46279\n",
      "Spark master: yarn, Application Id: application_1711307687799_0053\n",
      "Time taken: 4.578 seconds\n",
      "order_items\n",
      "orders\n",
      "Time taken: 2.156 seconds, Fetched 2 row(s)\n",
      "Job [3b57877c821e40c183427f9a57b1225c] finished successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=khazdataprocdev -e \"USE retail_bronze_db;SHOW tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/bd3c97171c03464da1a5dae027b3a533/\n",
      "driverOutputResourceUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/bd3c97171c03464da1a5dae027b3a533/driveroutput\n",
      "jobUuid: 22c53fb5-3760-3104-ae06-f08307a6d8c8\n",
      "placement:\n",
      "  clusterName: khazdataprocdev\n",
      "  clusterUuid: d1f87e3a-5d73-4d88-b893-fc5dee563e03\n",
      "reference:\n",
      "  jobId: bd3c97171c03464da1a5dae027b3a533\n",
      "  projectId: wired-method-417107\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - USE retail_bronze_db;SELECT count(*) FROM orders\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2024-04-21T07:54:01.496500Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2024-04-21T07:53:23.431421Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2024-04-21T07:53:23.463862Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2024-04-21T07:53:23.684901Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.184.0.2\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal.:8088/proxy/application_1711307687799_0054/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [bd3c97171c03464da1a5dae027b3a533] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "24/04/21 07:53:31 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/04/21 07:53:31 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/04/21 07:53:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/04/21 07:53:31 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark Web UI available at http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal:38477\n",
      "Spark master: yarn, Application Id: application_1711307687799_0054\n",
      "Time taken: 5.073 seconds\n",
      "68883\n",
      "Time taken: 10.807 seconds, Fetched 1 row(s)\n",
      "Job [bd3c97171c03464da1a5dae027b3a533] finished successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=khazdataprocdev -e \"USE retail_bronze_db;SELECT count(*) FROM orders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/dd6d88e86c204db4868801538877b7be/\n",
      "driverOutputResourceUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/dd6d88e86c204db4868801538877b7be/driveroutput\n",
      "jobUuid: 6dd8d56a-28a8-3c09-9f3b-9ad35bbe6b7f\n",
      "placement:\n",
      "  clusterName: khazdataprocdev\n",
      "  clusterUuid: d1f87e3a-5d73-4d88-b893-fc5dee563e03\n",
      "reference:\n",
      "  jobId: dd6d88e86c204db4868801538877b7be\n",
      "  projectId: wired-method-417107\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - USE retail_gold_db;SHOW tables\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2024-04-21T07:54:56.521041Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2024-04-21T07:54:28.334290Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2024-04-21T07:54:28.369184Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2024-04-21T07:54:28.607233Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.184.0.2\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal.:8088/proxy/application_1711307687799_0055/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [dd6d88e86c204db4868801538877b7be] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "24/04/21 07:54:35 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/04/21 07:54:36 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/04/21 07:54:36 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/04/21 07:54:36 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark Web UI available at http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal:41331\n",
      "Spark master: yarn, Application Id: application_1711307687799_0055\n",
      "Time taken: 5.479 seconds\n",
      "daily_product_revenue\n",
      "Time taken: 3.188 seconds, Fetched 1 row(s)\n",
      "Job [dd6d88e86c204db4868801538877b7be] finished successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=khazdataprocdev -e \"USE retail_gold_db;SHOW tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: true"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [77bafe026b2c4fd3993f313a75974445] submitted.\n",
      "Waiting for job output...\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "24/04/21 07:55:28 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/04/21 07:55:29 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/04/21 07:55:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/04/21 07:55:29 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "Spark Web UI available at http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal:43759\n",
      "Spark master: yarn, Application Id: application_1711307687799_0056\n",
      "Time taken: 5.59 seconds\n",
      "2013-08-09 00:00:00.0\t1073\tPENDING\t3\t599.97\n",
      "2013-08-11 00:00:00.0\t365\tCOMPLETE\t33\t1979.67\n",
      "2013-08-14 00:00:00.0\t403\tCANCELED\t1\t129.99\n",
      "2013-09-04 00:00:00.0\t703\tPENDING_PAYMENT\t4\t79.96\n",
      "2013-10-07 00:00:00.0\t191\tPENDING_PAYMENT\t18\t1799.82\n",
      "2013-10-12 00:00:00.0\t403\tPENDING\t11\t1429.89\n",
      "2013-10-13 00:00:00.0\t1004\tPROCESSING\t11\t4399.78\n",
      "2013-08-01 00:00:00.0\t957\tSUSPECTED_FRAUD\t2\t599.96\n",
      "2013-09-03 00:00:00.0\t191\tPENDING\t11\t1099.89\n",
      "2013-09-16 00:00:00.0\t818\tCOMPLETE\t1\t47.99\n",
      "Time taken: 8.431 seconds, Fetched 10 row(s)\n",
      "Job [77bafe026b2c4fd3993f313a75974445] finished successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "driverControlFilesUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/77bafe026b2c4fd3993f313a75974445/\n",
      "driverOutputResourceUri: gs://dataproc-staging-asia-southeast2-138920929384-yzz5grop/google-cloud-dataproc-metainfo/d1f87e3a-5d73-4d88-b893-fc5dee563e03/jobs/77bafe026b2c4fd3993f313a75974445/driveroutput\n",
      "jobUuid: 28ed1467-d39d-3fa6-b8cb-8325f087c460\n",
      "placement:\n",
      "  clusterName: khazdataprocdev\n",
      "  clusterUuid: d1f87e3a-5d73-4d88-b893-fc5dee563e03\n",
      "reference:\n",
      "  jobId: 77bafe026b2c4fd3993f313a75974445\n",
      "  projectId: wired-method-417107\n",
      "sparkSqlJob:\n",
      "  queryList:\n",
      "    queries:\n",
      "    - USE retail_gold_db;SELECT * FROM daily_product_revenue LIMIT 10\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2024-04-21T07:55:56.578256Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2024-04-21T07:55:21.604373Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2024-04-21T07:55:21.634005Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2024-04-21T07:55:21.927982Z'\n",
      "yarnApplications:\n",
      "- name: SparkSQL::10.184.0.2\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://khazdataprocdev-m.asia-southeast2-c.c.wired-method-417107.internal.:8088/proxy/application_1711307687799_0056/\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit spark-sql --cluster=khazdataprocdev -e \"USE retail_gold_db;SELECT * FROM daily_product_revenue LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deg-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a9d607f6995d470a72ac62c14cbba774ae3a8ede2bb7bb3a284130b245adccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
